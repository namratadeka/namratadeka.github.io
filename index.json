[{"authors":["admin"],"categories":null,"content":"Hello! I am a master’s student at UBC, Vancouver working on causal and fair representation learning using statistical kernel-based measures under the supervision of Dr. D.J. Sutherland while also collaborating with Dr. Arthur Gretton from the Gatsby Computational Neuroscience Unit at UCL.\nI am also a machine learning research intern at Borealis AI and have previously interned with Dr. Amir Zamir in the Visual Intelligence and Learning Lab at EPFL where I worked on learning sparse representations of articulated objects from videos and optical flow to create robotic object models.\nPrior to starting grad school, I was a research fellow at Wadhwani AI for two years where I was involved in the research and development of an AI-powered visual screening tool to detect low birth-weight (\u0026lt;2.5kg) babies in rural India where primary healthcare is inadequate. I have also interned at Microsot Research India\u0026rsquo;s Applied Sciences group on prototyping machine learning techniques to identify highly imbalanced P.I.I. attributes from massive customer databases for the EU GDPR mandate.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://namratadeka.github.io/author/namrata-deka/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/namrata-deka/","section":"authors","summary":"Hello! I am a master’s student at UBC, Vancouver working on causal and fair representation learning using statistical kernel-based measures under the supervision of Dr. D.J. Sutherland while also collaborating with Dr.","tags":null,"title":"Namrata Deka","type":"authors"},{"authors":null,"categories":null,"content":"","date":1668520800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668520800,"objectID":"eb03bbde0cf97cdf855a312876ff0f44","permalink":"https://namratadeka.github.io/publication/circe/","publishdate":"2022-11-01T00:00:00Z","relpermalink":"/publication/circe/","section":"publication","summary":"We introduce the Conditional Independence Regression CovariancE(CIRCE), a measure of conditional independence for multivariate continuous-valued variables. CIRCE applies as a regularizer in settings where we wish to learn neural features φ(X) of data X to estimate a target Y , while being conditionally independent of a distractor Z given Y . Both Z and Y are assumed to be continuous-valued but relatively low dimensional, whereas X and its features may be complex and high dimensional. Relevant settings include domain-invariant learning, fairness, and causal learning. The procedure requires just a single ridge regression from Y to kernelized features of Z, which can be done in advance. It is then only necessary to enforce independence of φ(X) from residuals of this regression, which is possible with attractive estimation properties and consistency guarantees. By contrast, earlier measures of conditional feature dependence require multiple regressions for each step of feature learning, resulting in more severe bias and variance, and greater computational cost. When sufficiently rich features are used, we establish that CIRCE is zero if and only if φ(X) ⊥⊥ Z | Y . In experiments we show superior performance to previous methods on challenging benchmarks, including learning conditionally invariant image features.","tags":["source themes"],"title":"Efficient Conditionally Invariant Representation Learning","type":"publication"},{"authors":null,"categories":null,"content":"","date":1668520800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668520800,"objectID":"c62ea862befd2a901d0f695551077988","permalink":"https://namratadeka.github.io/publication/mmd-b-fair/","publishdate":"2022-11-01T00:00:00Z","relpermalink":"/publication/mmd-b-fair/","section":"publication","summary":"We introduce a method, MMD-B-Fair, to learn fair representations of data via kernel two-sample testing. We find neural features of our data where a maximum mean discrepancy (MMD) test cannot distinguish between different values of sensitive attributes, while preserving information about the target. Minimizing the power of an MMD test is more difficult than maximizing it (as done in previous work), because the test threshold's complex behavior cannot be simply ignored. Our method exploits the simple asymptotics of block testing schemes to efficiently find fair representations without requiring the complex adversarial optimization or generative modelling schemes widely used by existing work on fair representation learning. We evaluate our approach on various datasets, showing its ability to \"hide\" information about sensitive attributes, and its effectiveness in downstream transfer tasks.","tags":["source themes"],"title":"MMD-B-Fair: Learning Fair Representations with Statistical Testing","type":"publication"}]